2025-03-11 15:07:26 [scrapy.utils.log] INFO: Scrapy 2.9.0 started (bot: kp_news_crawler)
2025-03-11 15:07:26 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.7.6 (default, Jan  8 2020, 13:42:34) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.2, Platform Darwin-22.6.0-x86_64-i386-64bit
2025-03-11 15:07:26 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'kp_news_crawler',
 'CONCURRENT_REQUESTS': 8,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'kp_news_crawler.log',
 'LOG_LEVEL': 'INFO',
 'MEMUSAGE_LIMIT_MB': 2048,
 'MEMUSAGE_WARNING_MB': 1024,
 'NEWSPIDER_MODULE': 'kp_news_crawler.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_TIMES': 3,
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['kp_news_crawler.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'KP News Crawler (+your-contact-email@example.com)'}
2025-03-11 15:07:26 [scrapy.extensions.telnet] INFO: Telnet Password: cf9241cff797e7d0
2025-03-11 15:07:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-03-11 15:07:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-11 15:07:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-11 15:07:27 [scrapy.middleware] INFO: Enabled item pipelines:
['kp_news_crawler.pipelines.PhotoDownloaderPipeline',
 'kp_news_crawler.pipelines.MongoDBPipeline']
2025-03-11 15:07:27 [scrapy.core.engine] INFO: Spider opened
2025-03-11 15:07:27 [root] INFO: Connected to MongoDB kp_news.articles
2025-03-11 15:07:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-11 15:07:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-11 15:07:27 [scrapy.extensions.memusage] INFO: Peak memory usage is 66MiB
2025-03-11 15:07:27 [scrapy-playwright] INFO: Starting download handler
2025-03-11 15:07:27 [scrapy-playwright] INFO: Starting download handler
2025-03-11 15:07:37 [scrapy-playwright] INFO: Launching browser chromium
2025-03-11 15:07:38 [scrapy-playwright] INFO: Browser chromium launched
2025-03-11 15:08:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.kp.ru/online/>
Traceback (most recent call last):
  File "/Applications/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 1694, in _inlineCallbacks
    cast(Failure, result).throwExceptionIntoGenerator, gen
  File "/Applications/anaconda3/lib/python3.7/site-packages/twisted/python/failure.py", line 518, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Applications/anaconda3/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
  File "/Applications/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 1065, in adapt
    extracted = result.result()
  File "/Applications/anaconda3/lib/python3.7/site-packages/scrapy_playwright/handler.py", line 311, in _download_request
    result = await self._download_request_with_page(request, page, spider)
  File "/Applications/anaconda3/lib/python3.7/site-packages/scrapy_playwright/handler.py", line 364, in _download_request_with_page
    await self._apply_page_methods(page, request, spider)
  File "/Applications/anaconda3/lib/python3.7/site-packages/scrapy_playwright/handler.py", line 422, in _apply_page_methods
    pm.result = await _maybe_await(method(*pm.args, **pm.kwargs))
  File "/Applications/anaconda3/lib/python3.7/site-packages/scrapy_playwright/_utils.py", line 16, in _maybe_await
    return await obj
  File "/Applications/anaconda3/lib/python3.7/site-packages/playwright/async_api/_generated.py", line 8302, in wait_for_selector
    selector=selector, timeout=timeout, state=state, strict=strict
  File "/Applications/anaconda3/lib/python3.7/site-packages/playwright/_impl/_page.py", line 352, in wait_for_selector
    return await self._main_frame.wait_for_selector(**locals_to_params(locals()))
  File "/Applications/anaconda3/lib/python3.7/site-packages/playwright/_impl/_frame.py", line 322, in wait_for_selector
    await self._channel.send("waitForSelector", locals_to_params(locals()))
  File "/Applications/anaconda3/lib/python3.7/site-packages/playwright/_impl/_connection.py", line 62, in send
    lambda: self.inner_send(method, params, False)
  File "/Applications/anaconda3/lib/python3.7/site-packages/playwright/_impl/_connection.py", line 482, in wrap_api_call
    return await cb()
  File "/Applications/anaconda3/lib/python3.7/site-packages/playwright/_impl/_connection.py", line 97, in inner_send
    result = next(iter(done)).result()
playwright._impl._api_types.TimeoutError: Timeout 30000ms exceeded.
=========================== logs ===========================
waiting for locator("div.news-feed__item") to be visible
============================================================
2025-03-11 15:08:11 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-11 15:08:11 [root] INFO: MongoDB connection closed
2025-03-11 15:08:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/playwright._impl._api_types.TimeoutError': 1,
 'downloader/request_bytes': 465,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1083,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 43.570304,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 11, 12, 8, 11, 19132),
 'log_count/ERROR': 1,
 'log_count/INFO': 17,
 'memusage/max': 69705728,
 'memusage/startup': 69705728,
 'playwright/context_count': 1,
 'playwright/context_count/max_concurrent': 1,
 'playwright/context_count/non_persistent': 1,
 'playwright/page_count': 1,
 'playwright/page_count/max_concurrent': 1,
 'playwright/request_count': 179,
 'playwright/request_count/method/GET': 114,
 'playwright/request_count/method/HEAD': 1,
 'playwright/request_count/method/POST': 64,
 'playwright/request_count/navigation': 2,
 'playwright/request_count/resource_type/document': 2,
 'playwright/request_count/resource_type/fetch': 24,
 'playwright/request_count/resource_type/font': 5,
 'playwright/request_count/resource_type/image': 44,
 'playwright/request_count/resource_type/media': 2,
 'playwright/request_count/resource_type/ping': 25,
 'playwright/request_count/resource_type/script': 38,
 'playwright/request_count/resource_type/xhr': 39,
 'playwright/response_count': 177,
 'playwright/response_count/method/GET': 114,
 'playwright/response_count/method/HEAD': 1,
 'playwright/response_count/method/POST': 62,
 'playwright/response_count/resource_type/document': 2,
 'playwright/response_count/resource_type/fetch': 24,
 'playwright/response_count/resource_type/font': 5,
 'playwright/response_count/resource_type/image': 44,
 'playwright/response_count/resource_type/media': 2,
 'playwright/response_count/resource_type/ping': 25,
 'playwright/response_count/resource_type/script': 38,
 'playwright/response_count/resource_type/xhr': 37,
 'response_received_count': 1,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 3, 11, 12, 7, 27, 448828)}
2025-03-11 15:08:11 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-11 15:08:11 [scrapy-playwright] INFO: Closing download handler
2025-03-11 19:25:07 [scrapy.utils.log] INFO: Scrapy 2.9.0 started (bot: kp_news_crawler)
2025-03-11 19:25:07 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.7.6 (default, Jan  8 2020, 13:42:34) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.2, Platform Darwin-22.6.0-x86_64-i386-64bit
2025-03-11 19:32:43 [scrapy.utils.log] INFO: Scrapy 2.9.0 started (bot: kp_news_crawler)
2025-03-11 19:32:43 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.7.6 (default, Jan  8 2020, 13:42:34) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.2, Platform Darwin-22.6.0-x86_64-i386-64bit
2025-03-11 19:32:43 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'kp_news_crawler',
 'CONCURRENT_REQUESTS': 8,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'kp_news_crawler.log',
 'LOG_LEVEL': 'INFO',
 'MEMUSAGE_LIMIT_MB': 2048,
 'MEMUSAGE_WARNING_MB': 1024,
 'NEWSPIDER_MODULE': 'kp_news_crawler.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_TIMES': 3,
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['kp_news_crawler.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'KP News Crawler (+your-contact-email@example.com)'}
2025-03-11 19:32:43 [scrapy.extensions.telnet] INFO: Telnet Password: 05c98771e12480db
2025-03-11 19:32:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-03-11 19:32:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-11 19:32:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-11 19:32:43 [scrapy.middleware] INFO: Enabled item pipelines:
['kp_news_crawler.pipelines.PhotoDownloaderPipeline',
 'kp_news_crawler.pipelines.MongoDBPipeline']
2025-03-11 19:32:43 [scrapy.core.engine] INFO: Spider opened
2025-03-11 19:32:43 [root] INFO: Connected to MongoDB kp_news.articles
2025-03-11 19:32:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-11 19:32:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-11 19:32:43 [scrapy.extensions.memusage] INFO: Peak memory usage is 66MiB
2025-03-11 19:32:43 [scrapy-playwright] INFO: Starting download handler
2025-03-11 19:32:43 [scrapy-playwright] INFO: Starting download handler
2025-03-11 19:32:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.kp.ru/online/> (referer: None)
Traceback (most recent call last):
  File "/Applications/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 893, in _runCallbacks
    current.result, *args, **kwargs
  File "/Applications/anaconda3/lib/python3.7/site-packages/scrapy/spiders/__init__.py", line 73, in _parse
    return self.parse(response, **kwargs)
  File "/Applications/anaconda3/lib/python3.7/site-packages/scrapy/spiders/__init__.py", line 77, in parse
    f"{self.__class__.__name__}.parse callback is not defined"
NotImplementedError: KpNewsSpider.parse callback is not defined
2025-03-11 19:32:56 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-11 19:32:56 [root] INFO: MongoDB connection closed
2025-03-11 19:32:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 64966,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 12.478493,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 11, 16, 32, 56, 170853),
 'httpcompression/response_bytes': 473038,
 'httpcompression/response_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 15,
 'memusage/max': 69750784,
 'memusage/startup': 69750784,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NotImplementedError': 1,
 'start_time': datetime.datetime(2025, 3, 11, 16, 32, 43, 692360)}
2025-03-11 19:32:56 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-11 19:32:56 [scrapy-playwright] INFO: Closing download handler
2025-03-11 20:56:41 [scrapy.utils.log] INFO: Scrapy 2.9.0 started (bot: kp_news_crawler)
2025-03-11 20:56:41 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.7.6 (default, Jan  8 2020, 13:42:34) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.2, Platform Darwin-22.6.0-x86_64-i386-64bit
2025-03-11 20:56:41 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'kp_news_crawler',
 'CONCURRENT_REQUESTS': 8,
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 2,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'kp_news_crawler.log',
 'LOG_LEVEL': 'INFO',
 'MEMUSAGE_LIMIT_MB': 2048,
 'MEMUSAGE_WARNING_MB': 1024,
 'NEWSPIDER_MODULE': 'kp_news_crawler.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_TIMES': 3,
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['kp_news_crawler.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'KP News Crawler (+your-contact-email@example.com)'}
2025-03-11 20:56:41 [scrapy.extensions.telnet] INFO: Telnet Password: 6fb970ec9d2c6e1d
2025-03-11 20:56:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-03-11 20:56:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-11 20:56:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-11 20:56:41 [scrapy.middleware] INFO: Enabled item pipelines:
['kp_news_crawler.pipelines.PhotoDownloaderPipeline',
 'kp_news_crawler.pipelines.MongoDBPipeline']
2025-03-11 20:56:41 [scrapy.core.engine] INFO: Spider opened
2025-03-11 20:56:41 [root] INFO: Connected to MongoDB kp_news.articles
2025-03-11 20:56:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-11 20:56:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-11 20:56:41 [scrapy.extensions.memusage] INFO: Peak memory usage is 66MiB
2025-03-11 20:56:41 [scrapy-playwright] INFO: Starting download handler
2025-03-11 20:56:41 [scrapy-playwright] INFO: Starting download handler
2025-03-11 20:56:54 [scrapy-playwright] INFO: Launching browser chromium
2025-03-11 20:56:54 [scrapy-playwright] INFO: Browser chromium launched
2025-03-11 20:57:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.kp.ru/online/>
Traceback (most recent call last):
  File "/Applications/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 1694, in _inlineCallbacks
    cast(Failure, result).throwExceptionIntoGenerator, gen
  File "/Applications/anaconda3/lib/python3.7/site-packages/twisted/python/failure.py", line 518, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Applications/anaconda3/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
  File "/Applications/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 1065, in adapt
    extracted = result.result()
  File "/Applications/anaconda3/lib/python3.7/site-packages/scrapy_playwright/handler.py", line 311, in _download_request
    result = await self._download_request_with_page(request, page, spider)
  File "/Applications/anaconda3/lib/python3.7/site-packages/scrapy_playwright/handler.py", line 364, in _download_request_with_page
    await self._apply_page_methods(page, request, spider)
  File "/Applications/anaconda3/lib/python3.7/site-packages/scrapy_playwright/handler.py", line 422, in _apply_page_methods
    pm.result = await _maybe_await(method(*pm.args, **pm.kwargs))
  File "/Applications/anaconda3/lib/python3.7/site-packages/scrapy_playwright/_utils.py", line 16, in _maybe_await
    return await obj
  File "/Applications/anaconda3/lib/python3.7/site-packages/playwright/async_api/_generated.py", line 9348, in wait_for_load_state
    await self._impl_obj.wait_for_load_state(state=state, timeout=timeout)
  File "/Applications/anaconda3/lib/python3.7/site-packages/playwright/_impl/_page.py", line 495, in wait_for_load_state
    return await self._main_frame.wait_for_load_state(**locals_to_params(locals()))
  File "/Applications/anaconda3/lib/python3.7/site-packages/playwright/_impl/_frame.py", line 242, in wait_for_load_state
    return await self._wait_for_load_state_impl(state, timeout)
  File "/Applications/anaconda3/lib/python3.7/site-packages/playwright/_impl/_frame.py", line 270, in _wait_for_load_state_impl
    await wait_helper.result()
playwright._impl._api_types.TimeoutError: Timeout 30000ms exceeded.
2025-03-11 20:57:32 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-11 20:57:32 [root] INFO: MongoDB connection closed
2025-03-11 20:57:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/playwright._impl._api_types.TimeoutError': 1,
 'downloader/request_bytes': 465,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1083,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 50.257779,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 11, 17, 57, 32, 124601),
 'log_count/ERROR': 1,
 'log_count/INFO': 17,
 'memusage/max': 69722112,
 'memusage/startup': 69722112,
 'playwright/context_count': 1,
 'playwright/context_count/max_concurrent': 1,
 'playwright/context_count/non_persistent': 1,
 'playwright/page_count': 1,
 'playwright/page_count/max_concurrent': 1,
 'playwright/request_count': 171,
 'playwright/request_count/method/GET': 113,
 'playwright/request_count/method/HEAD': 1,
 'playwright/request_count/method/POST': 57,
 'playwright/request_count/navigation': 1,
 'playwright/request_count/resource_type/document': 1,
 'playwright/request_count/resource_type/fetch': 26,
 'playwright/request_count/resource_type/font': 5,
 'playwright/request_count/resource_type/image': 49,
 'playwright/request_count/resource_type/ping': 16,
 'playwright/request_count/resource_type/script': 35,
 'playwright/request_count/resource_type/xhr': 39,
 'playwright/response_count': 157,
 'playwright/response_count/method/GET': 113,
 'playwright/response_count/method/HEAD': 1,
 'playwright/response_count/method/POST': 43,
 'playwright/response_count/resource_type/document': 1,
 'playwright/response_count/resource_type/fetch': 26,
 'playwright/response_count/resource_type/font': 5,
 'playwright/response_count/resource_type/image': 49,
 'playwright/response_count/resource_type/ping': 14,
 'playwright/response_count/resource_type/script': 35,
 'playwright/response_count/resource_type/xhr': 27,
 'response_received_count': 1,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 3, 11, 17, 56, 41, 866822)}
2025-03-11 20:57:32 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-11 20:57:32 [scrapy-playwright] INFO: Closing download handler
